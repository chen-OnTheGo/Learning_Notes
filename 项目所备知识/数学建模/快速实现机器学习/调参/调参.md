
推荐几篇关于调参的文章：
1. https://blog.csdn.net/qq_27782503/article/details/90449858
2. https://www.jianshu.com/p/5378ef009cae
3. https://www.bilibili.com/video/BV1pX4y1F7LM/ （# 应用机器学习|Part 3：超参数优化 MATLAB&Simulink）
4. https://ww2.mathworks.cn/help/stats/bayesopt.html

### 调参的定义

![](../../../../img/Pasted%20image%2020250828211327.png)


### 调参的目的

![](../../../../img/Pasted%20image%2020250828211403.png)

![](../../../../img/Pasted%20image%2020250828211454.png)
https://www.mathworks.com/help/releases/R2021a/stats/choose-a-classifier.html

可通过热力图来展示调参的优化效果：

![](../../../../img/Pasted%20image%2020250830233715.png)


### 调参的方法

常见的调参方法有一下三种：网格搜索、[随机搜索](调参.md#随机搜索)、[贝叶斯调参](调参.md#贝叶斯调参)。

#### 网格搜索

在指定的参数范围内，遍历每一种可能的情况，看哪组参数能使得模型的效果最好。（类似于枚举法）

若搜索的参数非常多，网格搜索就会很耗时间，这种情况下推荐用[贝叶斯调参](调参.md#贝叶斯调参)。若搜索的参数较少，用网格搜索可以找到最优参数。


![](../../../../img/Pasted%20image%2020250828211709.png)

![](../../../../img/Pasted%20image%2020250828211744.png)

网格搜索的优点：只要搜索的足够多，每种情况都尽量考虑到的话，我们有很大的可能性能找到最好的模型。

网格搜索的缺点：当要搜索的超参数比较多的时候，十分消耗计算资源和时间。


#### 随机搜索

随机的在参数空间中进行采样（类似于蒙特卡罗模拟的思想）

Bergstra 和 Bengio 两位学者在他们 2012 年发表的文章中，表明随机搜索比网格搜索更高效。在牺牲一些预测的准确性后，可以大大缩短搜索的时间。

参考论文：Bergstra J, Bengio Y. Random search for hyper-parameter optimization[M].JMLR.org, 2012.

#### 贝叶斯调参

一种启发式的调参策略（调参过程中用到了历史信息）。

原理可以参考：https://www.cnblogs.com/yangruiGB2312/p/9374377.html
或
https://baijiahao.baidu.com/s?id=1576049883424742

![](../../../../img/Pasted%20image%2020250828212536.png)


## 拓展

### 三个超参数的网络搜索

![](../../../../img/Pasted%20image%2020250829220537.png)


### 贝叶斯调参

[18. 拓展：贝叶斯调参_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1v64y1B7vJ?spm_id_from=333.788.player.switch&vd_source=e224f799d98aec1a6ea19d37bdd0dabe&p=22)